{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suspended-hearing",
   "metadata": {},
   "source": [
    "#### Is Monday Effect an Urban Myth?\n",
    "\n",
    "Author: Sungbin Youk\\\n",
    "Date: May 22nd, 2021\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-ballot",
   "metadata": {},
   "source": [
    "## Predicting the Stock Market\n",
    "\n",
    "It will be great if you can predict the changes in the stock market. It will make you rich. Isn't that everyone's dream? Unfortunately, [efficient market hypothesis](https://www.investopedia.com/terms/e/efficientmarkethypothesis.asp) postulates that generating a stable parameter that reflects the share prices is impossible as the share prices reflect all information. \n",
    "\n",
    "It would be against the efficient market hypothesis if there is a predictable *pattern* in the stock market. In 1973, [Frank Cross](https://www.jstor.org/stable/pdf/4529641.pdf?refreqid=excelsior%3Adeff8e6e9e2c4c0b275b4b03a21b9c13) documented a non-random movement in stock prices. Here are the main findings from examining the Standard & Poor's Composite Stock Index from 1953 to 1970:\n",
    "- The index have risen on Friday more often than on any other days of the week, and have risen least often on Monday. \n",
    "- When the Friday index declined, the Monday index was more likely to also see a decline. When the Friday index advanced, the Monday index was likely to remain static (neither advancing nor declining). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-dallas",
   "metadata": {},
   "source": [
    "## What is Monday Effect?\n",
    "\n",
    "Over the years, Frank Cross's findings were coined into what is now known as the **Monday Effect**. There are two different definitions of the monday effect (each corresponding to the two findings that are mentioned above). \n",
    "\n",
    "- Monday effect states that the returns on Monday are less than the other days of the week, and are often negative on average ([Pettengill, 2003](https://www.jstor.org/stable/pdf/23292837.pdf?refreqid=excelsior%3A6da162ff7d91746d901fc154171e6015)).\n",
    "- Monday effect states that the returns on the stock market on Monday, especially the first few hours, will follow the pattern of the previous Friday, espeically the last few hours ([Investopedia](https://www.investopedia.com/terms/m/mondayeffect.asp)). \n",
    "\n",
    "You may wonder what may be the reason behind this abnormality in the stock prices. As the existence of Monday effect is controversial (thus, the reason for our project), there isn't a clear answer. Some state that the stock returns are low on Monday because companies may hold on to bad news until the last day of stock trading (Friday), which in turn makes the next stock trading day (Monday) to take the hit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-lighter",
   "metadata": {},
   "source": [
    "## Our Objectives\n",
    "\n",
    "The objective of our project is in two-folds:\n",
    "1) [Arman and Lestari](https://www.atlantis-press.com/proceedings/icame-18/125917114) examined the Monday effect (the first definition) in the Indonesian Stock Exchange. We will first examine if we can examine the same results in the U.S. stock market.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-tutorial",
   "metadata": {},
   "source": [
    "## Summary of Arman and Lestari's Study\n",
    "\n",
    "Arman and Lestari examined the Monday effect by examining the banking sectors on the Indonesian stock market from 2014 to 2017. A one-sample t-test was conducted for each of the weekdays. The results indicated that the average stock return on Monday is -0.0006, which was not statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-economics",
   "metadata": {},
   "source": [
    "## Tackling Objective 1\n",
    "\n",
    "In our analysis, the stock returns of S&P 500 from 2014 to 2017 are examined. The stock return data are obtained from yfinance package in python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-emperor",
   "metadata": {},
   "source": [
    "### Importing Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opening-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import date\n",
    "import calendar\n",
    "import io\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-acquisition",
   "metadata": {},
   "source": [
    "### Importing the list of ticker for S&P 500 between 2014 to 2017\n",
    "\n",
    "The first step is to retrieve the companies that constituted S&P 500 in the past. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cross-multiple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cik</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>72741.0</td>\n",
       "      <td>1957-01-01</td>\n",
       "      <td>Eversource Energy</td>\n",
       "      <td>ES</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>874766.0</td>\n",
       "      <td>1957-01-01</td>\n",
       "      <td>Hartford Financial Svc.Gp.</td>\n",
       "      <td>HIG</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>435</td>\n",
       "      <td>1113169.0</td>\n",
       "      <td>1957-01-01</td>\n",
       "      <td>T. Rowe Price Group</td>\n",
       "      <td>TROW</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>349</td>\n",
       "      <td>1111711.0</td>\n",
       "      <td>1957-01-01</td>\n",
       "      <td>NiSource Inc.</td>\n",
       "      <td>NI</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>185</td>\n",
       "      <td>1109357.0</td>\n",
       "      <td>1957-01-01</td>\n",
       "      <td>Exelon Corp.</td>\n",
       "      <td>EXC</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        cik       date                        name value  \\\n",
       "0         183    72741.0 1957-01-01           Eversource Energy    ES   \n",
       "1         228   874766.0 1957-01-01  Hartford Financial Svc.Gp.   HIG   \n",
       "2         435  1113169.0 1957-01-01         T. Rowe Price Group  TROW   \n",
       "3         349  1111711.0 1957-01-01               NiSource Inc.    NI   \n",
       "4         185  1109357.0 1957-01-01                Exelon Corp.   EXC   \n",
       "\n",
       "       variable  \n",
       "0  added_ticker  \n",
       "1  added_ticker  \n",
       "2  added_ticker  \n",
       "3  added_ticker  \n",
       "4  added_ticker  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the csv file from a Github page which has a list of companies and when they were added or removed from S&P 500\n",
    "url = \"https://raw.githubusercontent.com/leosmigel/analyzingalpha/master/sp500-historical-components-and-changes/sp500_history.csv\"\n",
    "download = requests.get(url).content\n",
    "\n",
    "# Reading the downloaded content and turning it into a pandas dataframe\n",
    "df = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
    "\n",
    "#Turning the date column into a datetime object\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# Printing out the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "complex-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve the tickers in S&P 500 for a given timeframe\n",
    "def past_SP_ticker(end_date):\n",
    "    ticker_list = []\n",
    "    global df\n",
    "    for index,row in df.iterrows():\n",
    "        if row['date'] > end_date:\n",
    "            break\n",
    "        else:\n",
    "            if row['variable'] == \"added_ticker\":\n",
    "                ticker_list.append(row['value'])\n",
    "            elif row['value'] in ticker_list:\n",
    "                ticker_list.remove(row['value'])\n",
    "    return ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nutritional-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the past_SP_ticker() function to retrieve the tickers of S&P 500 for 2017. \n",
    "end_date = '20171231'\n",
    "date_time_obj = datetime.datetime.strptime(end_date,'%Y%m%d')\n",
    "SP_ticker_2017 = past_SP_ticker(date_time_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-fellow",
   "metadata": {},
   "source": [
    "### Creating a dataframe of stock returns for the identified S&P 500 constituents of 2017\n",
    "The next step is to obtain the daily stock returns of the selected companies. This requires several steps: obtain the stock data of the S&P 500 constituents of 2017, delete the missing values, calculate the log retruns, create a multilevel index (i.e., hierarchical index) with the days of the week"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-bronze",
   "metadata": {},
   "source": [
    "#### Obtaining the stock data of S&P 500 constituents of 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "superior-therapist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  488 of 488 completed\n",
      "\n",
      "33 Failed downloads:\n",
      "- STI: No data found, symbol may be delisted\n",
      "- Q: No data found for this date range, symbol may be delisted\n",
      "- VIAB: No data found, symbol may be delisted\n",
      "- JEC: No data found, symbol may be delisted\n",
      "- RTN: No data found, symbol may be delisted\n",
      "- NBL: No data found, symbol may be delisted\n",
      "- UA-C: No data found, symbol may be delisted\n",
      "- KFT: No data found for this date range, symbol may be delisted\n",
      "- LUK: No data found for this date range, symbol may be delisted\n",
      "- CXO: No data found, symbol may be delisted\n",
      "- WCG: No data found, symbol may be delisted\n",
      "- BRK.B: No data found, symbol may be delisted\n",
      "- ETFC: No data found, symbol may be delisted\n",
      "- TIF: No data found, symbol may be delisted\n",
      "- SYMC: No data found, symbol may be delisted\n",
      "- DLPH: No data found, symbol may be delisted\n",
      "- MYL: No data found, symbol may be delisted\n",
      "- GGP: No data found for this date range, symbol may be delisted\n",
      "- FOXA: Data doesn't exist for startDate = 1388448000, endDate = 1514678400\n",
      "- HCP: No data found, symbol may be delisted\n",
      "- CELG: No data found, symbol may be delisted\n",
      "- TSS: No data found, symbol may be delisted\n",
      "- CBS: No data found, symbol may be delisted\n",
      "- BF.B: No data found for this date range, symbol may be delisted\n",
      "- UTX: No data found, symbol may be delisted\n",
      "- PCLN: No data found for this date range, symbol may be delisted\n",
      "- ARNC: Data doesn't exist for startDate = 1388448000, endDate = 1514678400\n",
      "- CTL: No data found, symbol may be delisted\n",
      "- TYC: No data found for this date range, symbol may be delisted\n",
      "- FOX: Data doesn't exist for startDate = 1388448000, endDate = 1514678400\n",
      "- BBT: No data found, symbol may be delisted\n",
      "- KORS: No data found for this date range, symbol may be delisted\n",
      "- BHGE: No data found, symbol may be delisted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">Adj Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADI</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>38.247643</td>\n",
       "      <td>23.804220</td>\n",
       "      <td>108.380943</td>\n",
       "      <td>17.819059</td>\n",
       "      <td>38.220161</td>\n",
       "      <td>62.277599</td>\n",
       "      <td>33.028294</td>\n",
       "      <td>70.729378</td>\n",
       "      <td>59.880001</td>\n",
       "      <td>42.959011</td>\n",
       "      <td>...</td>\n",
       "      <td>1752800.0</td>\n",
       "      <td>1215400.0</td>\n",
       "      <td>8509600.0</td>\n",
       "      <td>434400.0</td>\n",
       "      <td>2033475.0</td>\n",
       "      <td>558000.0</td>\n",
       "      <td>2966800.0</td>\n",
       "      <td>650000.0</td>\n",
       "      <td>1077400.0</td>\n",
       "      <td>2270400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>37.592236</td>\n",
       "      <td>23.907927</td>\n",
       "      <td>107.460464</td>\n",
       "      <td>17.568451</td>\n",
       "      <td>37.619469</td>\n",
       "      <td>61.905617</td>\n",
       "      <td>32.942123</td>\n",
       "      <td>69.791710</td>\n",
       "      <td>59.290001</td>\n",
       "      <td>41.567257</td>\n",
       "      <td>...</td>\n",
       "      <td>3192300.0</td>\n",
       "      <td>3436800.0</td>\n",
       "      <td>11028100.0</td>\n",
       "      <td>1025400.0</td>\n",
       "      <td>3977691.0</td>\n",
       "      <td>765100.0</td>\n",
       "      <td>2721200.0</td>\n",
       "      <td>868800.0</td>\n",
       "      <td>1356700.0</td>\n",
       "      <td>2576100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>38.067085</td>\n",
       "      <td>25.020357</td>\n",
       "      <td>110.535233</td>\n",
       "      <td>17.182550</td>\n",
       "      <td>37.851063</td>\n",
       "      <td>61.949898</td>\n",
       "      <td>33.295418</td>\n",
       "      <td>70.023994</td>\n",
       "      <td>59.160000</td>\n",
       "      <td>41.845615</td>\n",
       "      <td>...</td>\n",
       "      <td>2939400.0</td>\n",
       "      <td>1982700.0</td>\n",
       "      <td>9295600.0</td>\n",
       "      <td>623300.0</td>\n",
       "      <td>2763747.0</td>\n",
       "      <td>454500.0</td>\n",
       "      <td>2026800.0</td>\n",
       "      <td>1288200.0</td>\n",
       "      <td>1122500.0</td>\n",
       "      <td>2524900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-06</th>\n",
       "      <td>37.879818</td>\n",
       "      <td>25.482304</td>\n",
       "      <td>109.477676</td>\n",
       "      <td>17.276245</td>\n",
       "      <td>36.468731</td>\n",
       "      <td>61.728436</td>\n",
       "      <td>33.734875</td>\n",
       "      <td>69.284195</td>\n",
       "      <td>58.119999</td>\n",
       "      <td>41.609428</td>\n",
       "      <td>...</td>\n",
       "      <td>3382300.0</td>\n",
       "      <td>1970800.0</td>\n",
       "      <td>11848500.0</td>\n",
       "      <td>986700.0</td>\n",
       "      <td>5657131.0</td>\n",
       "      <td>849400.0</td>\n",
       "      <td>4083600.0</td>\n",
       "      <td>1414900.0</td>\n",
       "      <td>1988200.0</td>\n",
       "      <td>2763200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2928 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Close                                                          \\\n",
       "                    A        AAL         AAP       AAPL       ABBV        ABC   \n",
       "Date                                                                            \n",
       "2013-12-30        NaN        NaN         NaN        NaN        NaN        NaN   \n",
       "2013-12-31  38.247643  23.804220  108.380943  17.819059  38.220161  62.277599   \n",
       "2014-01-02  37.592236  23.907927  107.460464  17.568451  37.619469  61.905617   \n",
       "2014-01-03  38.067085  25.020357  110.535233  17.182550  37.851063  61.949898   \n",
       "2014-01-06  37.879818  25.482304  109.477676  17.276245  36.468731  61.728436   \n",
       "\n",
       "                                                        ...     Volume  \\\n",
       "                  ABT        ACN       ADBE        ADI  ...        XEL   \n",
       "Date                                                    ...              \n",
       "2013-12-30        NaN        NaN        NaN        NaN  ...        NaN   \n",
       "2013-12-31  33.028294  70.729378  59.880001  42.959011  ...  1752800.0   \n",
       "2014-01-02  32.942123  69.791710  59.290001  41.567257  ...  3192300.0   \n",
       "2014-01-03  33.295418  70.023994  59.160000  41.845615  ...  2939400.0   \n",
       "2014-01-06  33.734875  69.284195  58.119999  41.609428  ...  3382300.0   \n",
       "\n",
       "                                                                              \\\n",
       "                 XLNX         XOM       XRAY        XRX       XYL        YUM   \n",
       "Date                                                                           \n",
       "2013-12-30        NaN         NaN        NaN        NaN       NaN        NaN   \n",
       "2013-12-31  1215400.0   8509600.0   434400.0  2033475.0  558000.0  2966800.0   \n",
       "2014-01-02  3436800.0  11028100.0  1025400.0  3977691.0  765100.0  2721200.0   \n",
       "2014-01-03  1982700.0   9295600.0   623300.0  2763747.0  454500.0  2026800.0   \n",
       "2014-01-06  1970800.0  11848500.0   986700.0  5657131.0  849400.0  4083600.0   \n",
       "\n",
       "                                             \n",
       "                  ZBH       ZION        ZTS  \n",
       "Date                                         \n",
       "2013-12-30        NaN        NaN        NaN  \n",
       "2013-12-31   650000.0  1077400.0  2270400.0  \n",
       "2014-01-02   868800.0  1356700.0  2576100.0  \n",
       "2014-01-03  1288200.0  1122500.0  2524900.0  \n",
       "2014-01-06  1414900.0  1988200.0  2763200.0  \n",
       "\n",
       "[5 rows x 2928 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the ticker to obtain stock prices from yfinance\n",
    "rawdata = yf.download(SP_ticker_2017, start=\"2013-12-31\", end=\"2017-12-31\")\n",
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-monthly",
   "metadata": {},
   "source": [
    "#### Deleting the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "opposite-crowd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     488.000000\n",
       "mean       82.977459\n",
       "std       262.763277\n",
       "min         3.000000\n",
       "25%         3.000000\n",
       "50%         3.000000\n",
       "75%         3.000000\n",
       "max      1011.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the missing values in terms of rows\n",
    "rawdata['Adj Close'].isna().sum(axis=0).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "english-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making an list of tuples for tickers that has more than 3 missing values\n",
    "high_missing_ticker = rawdata['Adj Close'].isna().sum(axis=0) > 3\n",
    "high_missing_ticker_list = high_missing_ticker[high_missing_ticker].index.tolist()\n",
    "high_missing_ticker_tuples = list()\n",
    "for i in ['Adj Close', 'Open', 'Close', 'High' ,'Low', 'Volume']:\n",
    "    high_missing_ticker_tuples += list(zip([i]*len(high_missing_ticker_list),high_missing_ticker_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interesting-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding columns (i.e., tickers) that has more than 3 missing values \n",
    "rawdata = rawdata.drop(high_missing_ticker_tuples, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "enclosed-composite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2013-12-30', '2016-01-18', '2017-01-02'], dtype='datetime64[ns]', name='Date', freq=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding out the dates that all tickers (columns) have missing values\n",
    "missingdate =rawdata.isna().sum(axis=1) > 0\n",
    "missingdate[missingdate].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "passing-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row with the index of 2013-12-31 will be deleted as it is out of the scope of our data (2014~2017)\n",
    "rawdata = rawdata.drop(pd.Timestamp('2013-12-30'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "healthy-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows with the index of 2017-01-02 and 2017-02-20 are replaced with the values from the previous date\n",
    "rawdata = rawdata.fillna(method= 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "distinct-wagon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check to see if all the missing values were either removed or replaced\n",
    "(rawdata.isna().sum(axis=None)>0).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-perception",
   "metadata": {},
   "source": [
    "#### Calculating the log returns for closing price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "concerned-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the log returns from stock prices\n",
    "logret = np.log(rawdata['Close']).diff()\n",
    "logret.columns = pd.MultiIndex.from_product([['logreturn'], logret.columns])\n",
    "# Joining logret and rawdata \n",
    "rawdata = rawdata.join(logret)\n",
    "# row with the index of 2013-12-31 will be deleted as it is out of the scope of our data (2014~2017)\n",
    "rawdata = rawdata.drop(pd.Timestamp('2013-12-31'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "express-rating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After preprocessing the data, we have idenified the log returns of 438 companies, which were included in S&P500 in 2017. To recap, we are examining the stock returns from 2014 to 2017. Therefore, we will be examining the stock returns of 1010 days\n"
     ]
    }
   ],
   "source": [
    "print(\"After preprocessing the data, we have idenified the log returns of {} companies, which were included in S&P500 in 2017. To recap, we are examining the stock returns from 2014 to 2017. Therefore, we will be examining the stock returns of {} days\".format(len(logret.columns), len(logret)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-atmosphere",
   "metadata": {},
   "source": [
    "#### Creating a new columns for days of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "located-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The day of the week is added as a new index (creating a hierarchical index)\n",
    "rawdata['days of week'] = [calendar.day_name[day.weekday()] for day in rawdata.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-talent",
   "metadata": {},
   "source": [
    "#### Exporting dataframe as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mature-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata.to_csv('Sungbin2014_2017_SP500.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-extension",
   "metadata": {},
   "source": [
    "#### Creating a multilevel index: Adding the week of day as an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "spoken-connecticut",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected 1009 rows, received array of length 1010",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1aff43b1aead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrawdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'days of week'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   4596\u001b[0m                 \u001b[0;31m# check newest element against length of calling frame, since\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4597\u001b[0m                 \u001b[0;31m# ensure_index_from_sequences would not raise for append=False.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4598\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   4599\u001b[0m                     \u001b[0;34mf\"Length mismatch: Expected {len(self)} rows, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4600\u001b[0m                     \u001b[0;34mf\"received array of length {len(arrays[-1])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected 1009 rows, received array of length 1010"
     ]
    }
   ],
   "source": [
    "rawdata = rawdata.set_index(['days of week', logret.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-philosophy",
   "metadata": {},
   "source": [
    "### Analyzing the Monday Effect\n",
    "The next step is to analyze the Monday effect. First, as done in Arman and Lestari's research, one-sample t-test is conducted for each day of the week. The test value is 0. Therefore, a significant result indicates that it is highly unlikely to have obtained the average log stock returns on a specific day of the week given that the null hypothesis is true (i.e. the average log stock return is 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "immune-opera",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day\n",
       "Friday       0.000360\n",
       "Monday      -0.000040\n",
       "Thursday     0.000372\n",
       "Tuesday      0.000450\n",
       "Wednesday    0.001083\n",
       "dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before we get into conducting one sample t-test, \n",
    "# let's look at the mean of log stock returns for each day of the week\n",
    "logret.groupby(level=0).mean().mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-consultancy",
   "metadata": {},
   "source": [
    "Wow! Unlike other days of the week (where the average log stock return is positive), Monday has a negative log stock returns. Let's see if this value is statistically significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "according-ceremony",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "NumExpr 2 does not support Unicode as a dtype.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-523f051855a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttest_1samp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mttest_1samp\u001b[0;34m(a, popmean, axis, nan_policy)\u001b[0m\n\u001b[1;32m   5313\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_chk_asarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5315\u001b[0;31m     \u001b[0mcontains_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_contains_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan_policy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontains_nan\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnan_policy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'omit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36m_contains_nan\u001b[0;34m(a, nan_policy)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# e.g. np.isnan(a).any()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mcontains_nan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# This can happen when attempting to sum things which are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2241\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   2242\u001b[0m                           initial=initial, where=where)\n\u001b[1;32m   2243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[1;32m    662\u001b[0m                 \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_to_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mdispatch_to_series\u001b[0;34m(left, right, func, axis)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# i.e. scalar, faster than checking np.ndim(right) == 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \"\"\"\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_op_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0muse_numexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_numexpr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_bool_arith_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mb_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         result = ne.evaluate(\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0;34mf\"a_value {op_str} b_value\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mlocal_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"a_value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b_value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/numexpr/necompiler.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(ex, local_dict, global_dict, out, order, casting, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;31m# Create a signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m     signature = [(name, getType(arg)) for (name, arg) in\n\u001b[0m\u001b[1;32m    824\u001b[0m                  zip(names, arguments)]\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/numexpr/necompiler.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;31m# Create a signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m     signature = [(name, getType(arg)) for (name, arg) in\n\u001b[0m\u001b[1;32m    824\u001b[0m                  zip(names, arguments)]\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/numexpr/necompiler.py\u001b[0m in \u001b[0;36mgetType\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'U'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NumExpr 2 does not support Unicode as a dtype.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown type %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: NumExpr 2 does not support Unicode as a dtype."
     ]
    }
   ],
   "source": [
    "scipy.stats.ttest_1samp(logret.groupby(level=0),0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
