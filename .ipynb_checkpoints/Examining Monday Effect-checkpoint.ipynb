{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "polar-advocacy",
   "metadata": {},
   "source": [
    "# Is Monday Effect an Urban Myth?\n",
    "\n",
    "**Authors**: Blythe King, Dinggyue Lie, Lucy (Yu) Xue\\*, Sungbin Youk\\\n",
    "**Date**: May 30th, 2021\\\n",
    "**Description**: As a final project for PSTAT 234 in University of California, Santa Barbara, the authors examined the presence of Monday effect. \\\n",
    "The authors equally contributed to the project. The names of the authors are in an alphabetical order. The corresponding author is indicated with *.\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-nature",
   "metadata": {},
   "source": [
    "**Table of Contents**\n",
    "1. [Introduction](#introduction)\\\n",
    "    A. [Predicting the Stock Market](#predicting-the-stock-market)\\\n",
    "    B. [What is Monday Effect](#what-is-monday-effect)\\\n",
    "    C. [Our Objectives](#our-objectives)\n",
    "2. [Tackling Objective 1](#tackling-objective-1)\n",
    "3. [Tackling Objective 2](#tackling-objective-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-wilson",
   "metadata": {},
   "source": [
    "## Introduction<a clas =\"anchor\" id = \"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-great",
   "metadata": {},
   "source": [
    "### Predicting the Stock Market <a clas =\"anchor\" id = \"predicting-the-stock-market\"></a>\n",
    "\n",
    "It will be great if you can predict the changes in the stock market. It will make you rich. Isn't that everyone's dream? Unfortunately, [efficient market hypothesis](https://www.investopedia.com/terms/e/efficientmarkethypothesis.asp) postulates that generating a stable parameter that reflects the share prices is impossible as the share prices reflect all information. \n",
    "\n",
    "It would be against the efficient market hypothesis if there is a predictable *pattern* in the stock market. In 1973, [Frank Cross](https://www.jstor.org/stable/pdf/4529641.pdf?refreqid=excelsior%3Adeff8e6e9e2c4c0b275b4b03a21b9c13) documented a non-random movement in stock prices. Here are the main findings from examining the Standard & Poor's Composite Stock Index from 1953 to 1970:\n",
    "- The index have risen on Friday more often than on any other days of the week, and have risen least often on Monday. \n",
    "- When the Friday index declined, the Monday index was more likely to also see a decline. When the Friday index advanced, the Monday index was likely to remain static (neither advancing nor declining). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-matrix",
   "metadata": {},
   "source": [
    "### What is Monday Effect? <a clas =\"anchor\" id = \"what-is-monday-effect\"></a>\n",
    "\n",
    "Over the years, Frank Cross's findings were coined into what is now known as the **Monday Effect**. There are two different definitions of the monday effect (each corresponding to the two findings that are mentioned above). \n",
    "\n",
    "- Monday effect states that the returns on Monday are less than the other days of the week, and are often negative on average ([Pettengill, 2003](https://www.jstor.org/stable/pdf/23292837.pdf?refreqid=excelsior%3A6da162ff7d91746d901fc154171e6015)).\n",
    "- Monday effect states that the returns on the stock market on Monday, especially the first few hours, will follow the pattern of the previous Friday, espeically the last few hours ([Investopedia](https://www.investopedia.com/terms/m/mondayeffect.asp)). \n",
    "\n",
    "You may wonder what may be the reason behind this abnormality in the stock prices. As the existence of Monday effect is controversial (thus, the reason for our project), there isn't a clear answer. Some state that the stock returns are low on Monday because companies may hold on to bad news until the last day of stock trading (Friday), which in turn makes the next stock trading day (Monday) to take the hit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-conversion",
   "metadata": {},
   "source": [
    "### Our Objectives <a clas =\"anchor\" id = \"our-objectives\"></a>\n",
    "\n",
    "The objective of our project is in two-folds:\n",
    "1) [Arman and Lestari](https://www.atlantis-press.com/proceedings/icame-18/125917114) examined the Monday effect (the first definition) in the Indonesian Stock Exchange. In their study, the first definition of Monday effect is used: The stock returns of Monday is less than the other days of the week. We will first examine if Monday effect is also present in the U.S. stock market.\\\n",
    "2) The second objective of this study is to examine the second definition of Monday effect: Monday's returns are correlated to that of Friday.\\\n",
    "3) We will take a step further and apply time series analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-pledge",
   "metadata": {},
   "source": [
    "----\n",
    "## Tackling Objective 1 <a clas =\"anchor\" id = \"tackling-objective-1\"></a>\n",
    "\n",
    "In our analysis, the stock returns of S&P 500 from 2014 to 2017 are examined. The stock return data are obtained from yfinance package in python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-bargain",
   "metadata": {},
   "source": [
    "### Summary of Arman and Lestari's Study\n",
    "\n",
    "Arman and Lestari examined the Monday effect by examining the banking sectors on the Indonesian stock market from 2014 to 2017. A one-sample t-test was conducted for each of the weekdays. The results indicated that the average stock return on Monday is -0.0006, which was not statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-monster",
   "metadata": {},
   "source": [
    "### Importing Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "sitting-shame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.8/site-packages (3.0.7)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.8/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import date\n",
    "import calendar\n",
    "import io\n",
    "from scipy import stats\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-working",
   "metadata": {},
   "source": [
    "### Importing the list of ticker for S&P 500 between 2014 to 2017\n",
    "\n",
    "The first step is to retrieve the companies that constituted S&P 500 in the past. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "floppy-sharing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cik</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>72741.0</td>\n",
       "      <td>1957-01-01</td>\n",
       "      <td>Eversource Energy</td>\n",
       "      <td>ES</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>874766.0</td>\n",
       "      <td>1957-01-01</td>\n",
       "      <td>Hartford Financial Svc.Gp.</td>\n",
       "      <td>HIG</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>435</td>\n",
       "      <td>1113169.0</td>\n",
       "      <td>1957-01-01</td>\n",
       "      <td>T. Rowe Price Group</td>\n",
       "      <td>TROW</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>349</td>\n",
       "      <td>1111711.0</td>\n",
       "      <td>1957-01-01</td>\n",
       "      <td>NiSource Inc.</td>\n",
       "      <td>NI</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>185</td>\n",
       "      <td>1109357.0</td>\n",
       "      <td>1957-01-01</td>\n",
       "      <td>Exelon Corp.</td>\n",
       "      <td>EXC</td>\n",
       "      <td>added_ticker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        cik       date                        name value  \\\n",
       "0         183    72741.0 1957-01-01           Eversource Energy    ES   \n",
       "1         228   874766.0 1957-01-01  Hartford Financial Svc.Gp.   HIG   \n",
       "2         435  1113169.0 1957-01-01         T. Rowe Price Group  TROW   \n",
       "3         349  1111711.0 1957-01-01               NiSource Inc.    NI   \n",
       "4         185  1109357.0 1957-01-01                Exelon Corp.   EXC   \n",
       "\n",
       "       variable  \n",
       "0  added_ticker  \n",
       "1  added_ticker  \n",
       "2  added_ticker  \n",
       "3  added_ticker  \n",
       "4  added_ticker  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the csv file from a Github page which has a list of companies and when they were added or removed from S&P 500\n",
    "url = \"https://raw.githubusercontent.com/leosmigel/analyzingalpha/master/sp500-historical-components-and-changes/sp500_history.csv\"\n",
    "download = requests.get(url).content\n",
    "\n",
    "# Reading the downloaded content and turning it into a pandas dataframe\n",
    "df = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
    "\n",
    "#Turning the date column into a datetime object\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# Printing out the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "premier-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve the tickers in S&P 500 for a given timeframe\n",
    "def past_SP_ticker(end_date):\n",
    "    ticker_list = []\n",
    "    global df\n",
    "    for index,row in df.iterrows():\n",
    "        if row['date'] > end_date:\n",
    "            break\n",
    "        else:\n",
    "            if row['variable'] == \"added_ticker\":\n",
    "                ticker_list.append(row['value'])\n",
    "            elif row['value'] in ticker_list:\n",
    "                ticker_list.remove(row['value'])\n",
    "    return ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "collected-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the past_SP_ticker() function to retrieve the tickers of S&P 500 for 2017. \n",
    "end_date = '20171231'\n",
    "date_time_obj = datetime.datetime.strptime(end_date,'%Y%m%d')\n",
    "SP_ticker_2017 = past_SP_ticker(date_time_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-commissioner",
   "metadata": {},
   "source": [
    "### Creating a dataframe of stock returns for the identified S&P 500 constituents of 2017\n",
    "The next step is to obtain the daily stock returns of the selected companies. This requires several steps: obtain the stock data of the S&P 500 constituents of 2017, delete the missing values, calculate the log retruns, create a multilevel index (i.e., hierarchical index) with the days of the week"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-performance",
   "metadata": {},
   "source": [
    "#### Obtaining the stock data of S&P 500 constituents of 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adult-sigma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  488 of 488 completed\n",
      "\n",
      "33 Failed downloads:\n",
      "- BRK.B: No data found, symbol may be delisted\n",
      "- TIF: No data found, symbol may be delisted\n",
      "- JEC: No data found, symbol may be delisted\n",
      "- FOX: Data doesn't exist for startDate = 1388448000, endDate = 1514678400\n",
      "- RTN: No data found, symbol may be delisted\n",
      "- SYMC: No data found, symbol may be delisted\n",
      "- BHGE: No data found, symbol may be delisted\n",
      "- KFT: No data found for this date range, symbol may be delisted\n",
      "- CTL: No data found, symbol may be delisted\n",
      "- BF.B: No data found for this date range, symbol may be delisted\n",
      "- ETFC: No data found, symbol may be delisted\n",
      "- STI: No data found, symbol may be delisted\n",
      "- GGP: No data found for this date range, symbol may be delisted\n",
      "- PCLN: No data found for this date range, symbol may be delisted\n",
      "- CBS: No data found, symbol may be delisted\n",
      "- TYC: No data found for this date range, symbol may be delisted\n",
      "- VIAB: No data found, symbol may be delisted\n",
      "- CXO: No data found, symbol may be delisted\n",
      "- Q: No data found for this date range, symbol may be delisted\n",
      "- MYL: No data found, symbol may be delisted\n",
      "- LUK: No data found for this date range, symbol may be delisted\n",
      "- UTX: No data found, symbol may be delisted\n",
      "- DLPH: No data found, symbol may be delisted\n",
      "- TSS: No data found, symbol may be delisted\n",
      "- HCP: No data found, symbol may be delisted\n",
      "- CELG: No data found, symbol may be delisted\n",
      "- NBL: No data found, symbol may be delisted\n",
      "- KORS: No data found for this date range, symbol may be delisted\n",
      "- WCG: No data found, symbol may be delisted\n",
      "- ARNC: Data doesn't exist for startDate = 1388448000, endDate = 1514678400\n",
      "- UA-C: No data found, symbol may be delisted\n",
      "- FOXA: Data doesn't exist for startDate = 1388448000, endDate = 1514678400\n",
      "- BBT: No data found, symbol may be delisted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Value</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Adj Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbol</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADI</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>38.247646</td>\n",
       "      <td>23.804220</td>\n",
       "      <td>108.574318</td>\n",
       "      <td>17.819059</td>\n",
       "      <td>38.783775</td>\n",
       "      <td>62.277599</td>\n",
       "      <td>33.028294</td>\n",
       "      <td>71.508987</td>\n",
       "      <td>59.880001</td>\n",
       "      <td>42.959011</td>\n",
       "      <td>...</td>\n",
       "      <td>1752800.0</td>\n",
       "      <td>1215400.0</td>\n",
       "      <td>8509600.0</td>\n",
       "      <td>434400.0</td>\n",
       "      <td>2033400.0</td>\n",
       "      <td>558000.0</td>\n",
       "      <td>2966800.0</td>\n",
       "      <td>650000.0</td>\n",
       "      <td>1077400.0</td>\n",
       "      <td>2270400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>37.592243</td>\n",
       "      <td>23.907927</td>\n",
       "      <td>107.652184</td>\n",
       "      <td>17.568451</td>\n",
       "      <td>38.174229</td>\n",
       "      <td>61.905617</td>\n",
       "      <td>32.942123</td>\n",
       "      <td>70.560982</td>\n",
       "      <td>59.290001</td>\n",
       "      <td>41.567257</td>\n",
       "      <td>...</td>\n",
       "      <td>3192300.0</td>\n",
       "      <td>3436800.0</td>\n",
       "      <td>11028100.0</td>\n",
       "      <td>1025400.0</td>\n",
       "      <td>3977600.0</td>\n",
       "      <td>765100.0</td>\n",
       "      <td>2721200.0</td>\n",
       "      <td>868800.0</td>\n",
       "      <td>1356700.0</td>\n",
       "      <td>2576100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>38.067078</td>\n",
       "      <td>25.020357</td>\n",
       "      <td>110.732445</td>\n",
       "      <td>17.182550</td>\n",
       "      <td>38.409229</td>\n",
       "      <td>61.949898</td>\n",
       "      <td>33.295418</td>\n",
       "      <td>70.795822</td>\n",
       "      <td>59.160000</td>\n",
       "      <td>41.845615</td>\n",
       "      <td>...</td>\n",
       "      <td>2939400.0</td>\n",
       "      <td>1982700.0</td>\n",
       "      <td>9295600.0</td>\n",
       "      <td>623300.0</td>\n",
       "      <td>2763700.0</td>\n",
       "      <td>454500.0</td>\n",
       "      <td>2026800.0</td>\n",
       "      <td>1288200.0</td>\n",
       "      <td>1122500.0</td>\n",
       "      <td>2524900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-06</th>\n",
       "      <td>37.879810</td>\n",
       "      <td>25.482304</td>\n",
       "      <td>109.672997</td>\n",
       "      <td>17.276245</td>\n",
       "      <td>37.006523</td>\n",
       "      <td>61.728436</td>\n",
       "      <td>33.734875</td>\n",
       "      <td>70.047867</td>\n",
       "      <td>58.119999</td>\n",
       "      <td>41.609428</td>\n",
       "      <td>...</td>\n",
       "      <td>3382300.0</td>\n",
       "      <td>1970800.0</td>\n",
       "      <td>11848500.0</td>\n",
       "      <td>986700.0</td>\n",
       "      <td>5657100.0</td>\n",
       "      <td>849400.0</td>\n",
       "      <td>4083600.0</td>\n",
       "      <td>1414900.0</td>\n",
       "      <td>1988200.0</td>\n",
       "      <td>2763200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2928 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Value       Adj Close                                                          \\\n",
       "Symbol              A        AAL         AAP       AAPL       ABBV        ABC   \n",
       "Date                                                                            \n",
       "2013-12-30        NaN        NaN         NaN        NaN        NaN        NaN   \n",
       "2013-12-31  38.247646  23.804220  108.574318  17.819059  38.783775  62.277599   \n",
       "2014-01-02  37.592243  23.907927  107.652184  17.568451  38.174229  61.905617   \n",
       "2014-01-03  38.067078  25.020357  110.732445  17.182550  38.409229  61.949898   \n",
       "2014-01-06  37.879810  25.482304  109.672997  17.276245  37.006523  61.728436   \n",
       "\n",
       "Value                                                   ...     Volume  \\\n",
       "Symbol            ABT        ACN       ADBE        ADI  ...        XEL   \n",
       "Date                                                    ...              \n",
       "2013-12-30        NaN        NaN        NaN        NaN  ...        NaN   \n",
       "2013-12-31  33.028294  71.508987  59.880001  42.959011  ...  1752800.0   \n",
       "2014-01-02  32.942123  70.560982  59.290001  41.567257  ...  3192300.0   \n",
       "2014-01-03  33.295418  70.795822  59.160000  41.845615  ...  2939400.0   \n",
       "2014-01-06  33.734875  70.047867  58.119999  41.609428  ...  3382300.0   \n",
       "\n",
       "Value                                                                         \\\n",
       "Symbol           XLNX         XOM       XRAY        XRX       XYL        YUM   \n",
       "Date                                                                           \n",
       "2013-12-30        NaN         NaN        NaN        NaN       NaN        NaN   \n",
       "2013-12-31  1215400.0   8509600.0   434400.0  2033400.0  558000.0  2966800.0   \n",
       "2014-01-02  3436800.0  11028100.0  1025400.0  3977600.0  765100.0  2721200.0   \n",
       "2014-01-03  1982700.0   9295600.0   623300.0  2763700.0  454500.0  2026800.0   \n",
       "2014-01-06  1970800.0  11848500.0   986700.0  5657100.0  849400.0  4083600.0   \n",
       "\n",
       "Value                                        \n",
       "Symbol            ZBH       ZION        ZTS  \n",
       "Date                                         \n",
       "2013-12-30        NaN        NaN        NaN  \n",
       "2013-12-31   650000.0  1077400.0  2270400.0  \n",
       "2014-01-02   868800.0  1356700.0  2576100.0  \n",
       "2014-01-03  1288200.0  1122500.0  2524900.0  \n",
       "2014-01-06  1414900.0  1988200.0  2763200.0  \n",
       "\n",
       "[5 rows x 2928 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the ticker to obtain stock prices from yfinance\n",
    "rawdata = yf.download(SP_ticker_2017, start=\"2013-12-31\", end=\"2017-12-31\")\n",
    "rawdata.columns = rawdata.columns.set_names(['Value', 'Symbol'])\n",
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-turkish",
   "metadata": {},
   "source": [
    "#### Deleting the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spatial-whole",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     488.000000\n",
       "mean       82.971311\n",
       "std       262.765093\n",
       "min         3.000000\n",
       "25%         3.000000\n",
       "50%         3.000000\n",
       "75%         3.000000\n",
       "max      1011.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the missing values in terms of rows\n",
    "rawdata['Close'].isna().sum(axis=0).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cooked-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making an list of tuples for tickers that has more than 3 missing values\n",
    "high_missing_ticker = rawdata['Close'].isna().sum(axis=0) > 3\n",
    "high_missing_ticker_list = high_missing_ticker[high_missing_ticker].index.tolist()\n",
    "high_missing_ticker_tuples = list()\n",
    "for i in ['Adj Close', 'Open', 'Close', 'High' ,'Low', 'Volume']:\n",
    "    high_missing_ticker_tuples += list(zip([i]*len(high_missing_ticker_list),high_missing_ticker_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "korean-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding columns (i.e., tickers) that has more than 3 missing values \n",
    "rawdata = rawdata.drop(high_missing_ticker_tuples, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "modified-november",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2013-12-30', '2016-01-18', '2017-02-20'], dtype='datetime64[ns]', name='Date', freq=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding out the dates that all tickers (columns) have missing values\n",
    "missingdate =rawdata.isna().sum(axis=1) > 0\n",
    "missingdate[missingdate].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "marine-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row with the index of 2013-12-31 will be deleted as it is out of the scope of our data (2014~2017)\n",
    "rawdata = rawdata.drop(pd.Timestamp('2013-12-30'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "amended-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows with the index of 2017-01-02 and 2017-02-20 are replaced with the values from the previous date\n",
    "rawdata = rawdata.fillna(method= 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "modern-mexico",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check to see if all the missing values were either removed or replaced\n",
    "(rawdata.isna().sum(axis=None)>0).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-hearing",
   "metadata": {},
   "source": [
    "#### Calculating the log returns for closing price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "governing-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the log returns from stock prices\n",
    "logret = np.log(rawdata['Close']).diff()\n",
    "logret.columns = pd.MultiIndex.from_product([['logreturn'], logret.columns])\n",
    "# Joining logret and rawdata \n",
    "rawdata = rawdata.join(logret)\n",
    "# row with the index of 2013-12-31 will be deleted as it is out of the scope of our data (2014~2017)\n",
    "rawdata = rawdata.drop(pd.Timestamp('2013-12-31'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "heavy-boundary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After preprocessing the data, we have idenified the log returns of 438 companies, which were included in S&P500 in 2017. To recap, we are examining the stock returns from 2014 to 2017. Therefore, we will be examining the stock returns of 1010 days\n"
     ]
    }
   ],
   "source": [
    "print(\"After preprocessing the data, we have idenified the log returns of {} companies, which were included in S&P500 in 2017. To recap, we are examining the stock returns from 2014 to 2017. Therefore, we will be examining the stock returns of {} days\".format(len(logret.columns), len(logret)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-champion",
   "metadata": {},
   "source": [
    "#### Creating a new columns for the industry information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "extreme-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the information about the tickers that are included in SP_ticker_2017\n",
    "industry_dic = dict()\n",
    "for item in SP_ticker_2017:\n",
    "    try:\n",
    "        industry_dic[item] = yf.Ticker(item).info['industry']\n",
    "    except:\n",
    "        industry_dic[item] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "according-interaction",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8b4a3f1488e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Adding the industry to a level of the column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrawdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindustry_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrawdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrawdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-8b4a3f1488e7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Adding the industry to a level of the column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrawdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindustry_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrawdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrawdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Adding the industry to a level of the column\n",
    "rawdata.columns = pd.MultiIndex.from_tuples([(value, industry_dic[ticker], ticker) for value, ticker in rawdata.columns])\n",
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-toner",
   "metadata": {},
   "source": [
    "#### Creating a new columns for days of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "needed-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The day of the week is added as a new index (creating a hierarchical index)\n",
    "rawdata['days'] = [calendar.day_name[day.weekday()] for day in rawdata.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-macintosh",
   "metadata": {},
   "source": [
    "#### Exporting dataframe as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "opened-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata.to_csv('SP500_2014_2017_multilevel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-auckland",
   "metadata": {},
   "source": [
    "#### Staking the Closing and Log returns into one dataframe\n",
    "\n",
    "For convenience in running some of the statistical analyses, the multilevel data of stock values are stacked into a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "nervous-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To easily stack the data, it is easier to delete the days and industry information.\n",
    "rawdata = rawdata.drop('days', axis =1)\n",
    "rawdata.columns = rawdata.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "organic-installation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>logreturn</th>\n",
       "      <th>days</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>A</td>\n",
       "      <td>37.592243</td>\n",
       "      <td>40.207439</td>\n",
       "      <td>40.844063</td>\n",
       "      <td>40.164520</td>\n",
       "      <td>40.844063</td>\n",
       "      <td>2678848.0</td>\n",
       "      <td>-0.017284</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>AAL</td>\n",
       "      <td>23.907927</td>\n",
       "      <td>25.360001</td>\n",
       "      <td>25.820000</td>\n",
       "      <td>25.059999</td>\n",
       "      <td>25.070000</td>\n",
       "      <td>8997900.0</td>\n",
       "      <td>0.004347</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>AAP</td>\n",
       "      <td>107.652184</td>\n",
       "      <td>109.739998</td>\n",
       "      <td>111.879997</td>\n",
       "      <td>109.290001</td>\n",
       "      <td>110.360001</td>\n",
       "      <td>542700.0</td>\n",
       "      <td>-0.008529</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Specialty Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>17.568451</td>\n",
       "      <td>19.754642</td>\n",
       "      <td>19.893929</td>\n",
       "      <td>19.715000</td>\n",
       "      <td>19.845715</td>\n",
       "      <td>234684800.0</td>\n",
       "      <td>-0.014164</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Consumer Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>38.174229</td>\n",
       "      <td>51.980000</td>\n",
       "      <td>52.330002</td>\n",
       "      <td>51.520000</td>\n",
       "      <td>52.119999</td>\n",
       "      <td>4569100.0</td>\n",
       "      <td>-0.015842</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Drug Manufacturers—General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Ticker   Adj Close       Close        High         Low  \\\n",
       "0 2014-01-02      A   37.592243   40.207439   40.844063   40.164520   \n",
       "1 2014-01-02    AAL   23.907927   25.360001   25.820000   25.059999   \n",
       "2 2014-01-02    AAP  107.652184  109.739998  111.879997  109.290001   \n",
       "3 2014-01-02   AAPL   17.568451   19.754642   19.893929   19.715000   \n",
       "4 2014-01-02   ABBV   38.174229   51.980000   52.330002   51.520000   \n",
       "\n",
       "         Open       Volume  logreturn      days                    Industry  \n",
       "0   40.844063    2678848.0  -0.017284  Thursday      Diagnostics & Research  \n",
       "1   25.070000    8997900.0   0.004347  Thursday                    Airlines  \n",
       "2  110.360001     542700.0  -0.008529  Thursday            Specialty Retail  \n",
       "3   19.845715  234684800.0  -0.014164  Thursday        Consumer Electronics  \n",
       "4   52.119999    4569100.0  -0.015842  Thursday  Drug Manufacturers—General  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The data is stacked \n",
    "stacked_rawdata = rawdata.stack()\n",
    "stacked_rawdata.reset_index(inplace=True)\n",
    "stacked_rawdata = stacked_rawdata.rename(columns = {'level_1':'Ticker'})\n",
    "\n",
    "# Days are added as a new column\n",
    "stacked_rawdata['days'] = [calendar.day_name[day.weekday()] for day in stacked_rawdata['Date']]\n",
    "\n",
    "# Industry information is added as a new column\n",
    "stacked_rawdata['Industry'] = [industry_dic[ticker] for ticker in stacked_rawdata['Ticker']]\n",
    "stacked_rawdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-convertible",
   "metadata": {},
   "source": [
    "#### Exporting dataframe as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "freelance-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_rawdata.to_csv('SP500_2014_2017_stacked.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-brass",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Tackling Objective 2\n",
    "\n",
    "The second objective is to examine the Monday effect on the lastest S&P 500 constituents. The process of obtaining the preprocessing the data is identical to that used for S&P500 for 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-fluid",
   "metadata": {},
   "source": [
    "### Creating a dataframe of stock returns for the latest S&P 500 constituents\n",
    "The list of constituents for the latest S&P500 are available in `list of sp500.xlsx` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "american-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500list = pd.read_excel('list of sp500.xlsx', engine='openpyxl')\n",
    "SP_ticker_2020 = SP500list['Symbol'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-variation",
   "metadata": {},
   "source": [
    "### Obtaining the stock data of latest S&P 500 constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fiscal-columbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  505 of 505 completed\n",
      "\n",
      "2 Failed downloads:\n",
      "- BRK.B: No data found, symbol may be delisted\n",
      "- BF.B: No data found for this date range, symbol may be delisted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Value</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Adj Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbol</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>65.777748</td>\n",
       "      <td>51.647556</td>\n",
       "      <td>104.610184</td>\n",
       "      <td>41.310070</td>\n",
       "      <td>81.751373</td>\n",
       "      <td>88.406036</td>\n",
       "      <td>192.490005</td>\n",
       "      <td>55.480598</td>\n",
       "      <td>145.921112</td>\n",
       "      <td>177.699997</td>\n",
       "      <td>...</td>\n",
       "      <td>2443400.0</td>\n",
       "      <td>2579900.0</td>\n",
       "      <td>11469300.0</td>\n",
       "      <td>1622300.0</td>\n",
       "      <td>877800.0</td>\n",
       "      <td>1747800.0</td>\n",
       "      <td>1765300.0</td>\n",
       "      <td>310600.0</td>\n",
       "      <td>2387100.0</td>\n",
       "      <td>2135600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>67.451401</td>\n",
       "      <td>51.014027</td>\n",
       "      <td>105.556801</td>\n",
       "      <td>41.302879</td>\n",
       "      <td>83.030678</td>\n",
       "      <td>88.735046</td>\n",
       "      <td>195.820007</td>\n",
       "      <td>55.603271</td>\n",
       "      <td>146.594574</td>\n",
       "      <td>181.039993</td>\n",
       "      <td>...</td>\n",
       "      <td>4114900.0</td>\n",
       "      <td>2453300.0</td>\n",
       "      <td>13957700.0</td>\n",
       "      <td>1533300.0</td>\n",
       "      <td>778800.0</td>\n",
       "      <td>2554900.0</td>\n",
       "      <td>1328800.0</td>\n",
       "      <td>253000.0</td>\n",
       "      <td>1575700.0</td>\n",
       "      <td>2328200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>66.945419</td>\n",
       "      <td>51.335667</td>\n",
       "      <td>109.451698</td>\n",
       "      <td>41.494736</td>\n",
       "      <td>82.557167</td>\n",
       "      <td>88.537621</td>\n",
       "      <td>199.250000</td>\n",
       "      <td>55.508900</td>\n",
       "      <td>148.330338</td>\n",
       "      <td>183.220001</td>\n",
       "      <td>...</td>\n",
       "      <td>2807000.0</td>\n",
       "      <td>3346500.0</td>\n",
       "      <td>10863000.0</td>\n",
       "      <td>1052400.0</td>\n",
       "      <td>796500.0</td>\n",
       "      <td>1971200.0</td>\n",
       "      <td>1073200.0</td>\n",
       "      <td>435200.0</td>\n",
       "      <td>3309200.0</td>\n",
       "      <td>2534000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3030 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Value       Adj Close                                                          \\\n",
       "Symbol              A        AAL         AAP       AAPL       ABBV        ABC   \n",
       "Date                                                                            \n",
       "2017-12-29        NaN        NaN         NaN        NaN        NaN        NaN   \n",
       "2018-01-01        NaN        NaN         NaN        NaN        NaN        NaN   \n",
       "2018-01-02  65.777748  51.647556  104.610184  41.310070  81.751373  88.406036   \n",
       "2018-01-03  67.451401  51.014027  105.556801  41.302879  83.030678  88.735046   \n",
       "2018-01-04  66.945419  51.335667  109.451698  41.494736  82.557167  88.537621   \n",
       "\n",
       "Value                                                      ...     Volume  \\\n",
       "Symbol            ABMD        ABT         ACN        ADBE  ...        XEL   \n",
       "Date                                                       ...              \n",
       "2017-12-29         NaN        NaN         NaN         NaN  ...        NaN   \n",
       "2018-01-01         NaN        NaN         NaN         NaN  ...        NaN   \n",
       "2018-01-02  192.490005  55.480598  145.921112  177.699997  ...  2443400.0   \n",
       "2018-01-03  195.820007  55.603271  146.594574  181.039993  ...  4114900.0   \n",
       "2018-01-04  199.250000  55.508900  148.330338  183.220001  ...  2807000.0   \n",
       "\n",
       "Value                                                                         \\\n",
       "Symbol           XLNX         XOM       XRAY       XYL        YUM        ZBH   \n",
       "Date                                                                           \n",
       "2017-12-29        NaN         NaN        NaN       NaN        NaN        NaN   \n",
       "2018-01-01        NaN         NaN        NaN       NaN        NaN        NaN   \n",
       "2018-01-02  2579900.0  11469300.0  1622300.0  877800.0  1747800.0  1765300.0   \n",
       "2018-01-03  2453300.0  13957700.0  1533300.0  778800.0  2554900.0  1328800.0   \n",
       "2018-01-04  3346500.0  10863000.0  1052400.0  796500.0  1971200.0  1073200.0   \n",
       "\n",
       "Value                                       \n",
       "Symbol          ZBRA       ZION        ZTS  \n",
       "Date                                        \n",
       "2017-12-29       NaN        NaN        NaN  \n",
       "2018-01-01       NaN        NaN        NaN  \n",
       "2018-01-02  310600.0  2387100.0  2135600.0  \n",
       "2018-01-03  253000.0  1575700.0  2328200.0  \n",
       "2018-01-04  435200.0  3309200.0  2534000.0  \n",
       "\n",
       "[5 rows x 3030 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the ticker to obtain stock prices from yfinance\n",
    "rawdata = yf.download(SP_ticker_2020, start=\"2017-12-30\", end=\"2021-05-28\")\n",
    "rawdata.columns = rawdata.columns.set_names(['Value', 'Symbol'])\n",
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-brief",
   "metadata": {},
   "source": [
    "#### Deleting the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chicken-platform",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    505.000000\n",
       "mean      12.192079\n",
       "std       73.824631\n",
       "min        3.000000\n",
       "25%        3.000000\n",
       "50%        3.000000\n",
       "75%        3.000000\n",
       "max      860.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the missing values in terms of rows\n",
    "rawdata['Close'].isna().sum(axis=0).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "smart-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making an list of tuples for tickers that has more than 3 missing values\n",
    "high_missing_ticker = rawdata['Close'].isna().sum(axis=0) > 3\n",
    "high_missing_ticker_list = high_missing_ticker[high_missing_ticker].index.tolist()\n",
    "high_missing_ticker_tuples = list()\n",
    "for i in ['Adj Close', 'Open', 'Close', 'High' ,'Low', 'Volume']:\n",
    "    high_missing_ticker_tuples += list(zip([i]*len(high_missing_ticker_list),high_missing_ticker_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "broad-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding columns (i.e., tickers) that has more than 3 missing values \n",
    "rawdata = rawdata.drop(high_missing_ticker_tuples, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "speaking-happening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2017-12-29', '2018-01-01', '2018-12-05'], dtype='datetime64[ns]', name='Date', freq=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding out the dates that all tickers (columns) have missing values\n",
    "missingdate =rawdata.isna().sum(axis=1) > 0\n",
    "missingdate[missingdate].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "incorrect-assistant",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"[Timestamp('2017-12-29 00:00:00')] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-99f4de21de74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# row with the index of 2017-12-29 will be deleted as it is out of the scope of our data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrawdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2017-12-29'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4165\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4166\u001b[0m         \"\"\"\n\u001b[0;32m-> 4167\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4168\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4169\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3887\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3888\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3889\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3921\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3922\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3923\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3924\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5287\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5288\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"[Timestamp('2017-12-29 00:00:00')] not found in axis\""
     ]
    }
   ],
   "source": [
    "# row with the index of 2017-12-29 will be deleted as it is out of the scope of our data\n",
    "rawdata = rawdata.drop(pd.Timestamp('2017-12-29'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "amateur-veteran",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"[Timestamp('2018-01-01 00:00:00')] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6fa9cc40a955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# rwo with the index of 2018-01-01 is deleted as it is missing values for all tickers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrawdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2018-01-01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4165\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4166\u001b[0m         \"\"\"\n\u001b[0;32m-> 4167\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4168\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4169\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3887\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3888\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3889\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3921\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3922\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3923\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3924\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5287\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5288\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"[Timestamp('2018-01-01 00:00:00')] not found in axis\""
     ]
    }
   ],
   "source": [
    "# rwo with the index of 2018-01-01 is deleted as it is missing values for all tickers\n",
    "rawdata = rawdata.drop(pd.Timestamp('2018-01-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "desirable-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row with the index of 2018-12-05 is replaced with the values from the previous date\n",
    "rawdata = rawdata.fillna(method= 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "younger-playback",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check to see if all the missing values were either removed or replaced\n",
    "(rawdata.isna().sum(axis=None)>0).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-sunrise",
   "metadata": {},
   "source": [
    "#### Calculating the log returns for closing price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "loved-congress",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: MultiIndex([('logreturn',    'A'),\n            ('logreturn',  'AAL'),\n            ('logreturn',  'AAP'),\n            ('logreturn', 'AAPL'),\n            ('logreturn', 'ABBV'),\n            ('logreturn',  'ABC'),\n            ('logreturn', 'ABMD'),\n            ('logreturn',  'ABT'),\n            ('logreturn',  'ACN'),\n            ('logreturn', 'ADBE'),\n            ...\n            ('logreturn',  'XEL'),\n            ('logreturn', 'XLNX'),\n            ('logreturn',  'XOM'),\n            ('logreturn', 'XRAY'),\n            ('logreturn',  'XYL'),\n            ('logreturn',  'YUM'),\n            ('logreturn',  'ZBH'),\n            ('logreturn', 'ZBRA'),\n            ('logreturn', 'ZION'),\n            ('logreturn',  'ZTS')],\n           length=495)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-db8a7ff2c92c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_product\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logreturn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Joining logret and rawdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrawdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   7872\u001b[0m         \u001b[0;36m5\u001b[0m  \u001b[0mK5\u001b[0m  \u001b[0mA5\u001b[0m  \u001b[0mNaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7873\u001b[0m         \"\"\"\n\u001b[0;32m-> 7874\u001b[0;31m         return self._join_compat(\n\u001b[0m\u001b[1;32m   7875\u001b[0m             \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrsuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7876\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   7888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7890\u001b[0;31m             return merge(\n\u001b[0m\u001b[1;32m   7891\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7892\u001b[0m                 \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     )\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         llabels, rlabels = _items_overlap_with_suffix(\n\u001b[0m\u001b[1;32m    671\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2095\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlsuffix\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2096\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"columns overlap but no suffix specified: {to_rename}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrenamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: columns overlap but no suffix specified: MultiIndex([('logreturn',    'A'),\n            ('logreturn',  'AAL'),\n            ('logreturn',  'AAP'),\n            ('logreturn', 'AAPL'),\n            ('logreturn', 'ABBV'),\n            ('logreturn',  'ABC'),\n            ('logreturn', 'ABMD'),\n            ('logreturn',  'ABT'),\n            ('logreturn',  'ACN'),\n            ('logreturn', 'ADBE'),\n            ...\n            ('logreturn',  'XEL'),\n            ('logreturn', 'XLNX'),\n            ('logreturn',  'XOM'),\n            ('logreturn', 'XRAY'),\n            ('logreturn',  'XYL'),\n            ('logreturn',  'YUM'),\n            ('logreturn',  'ZBH'),\n            ('logreturn', 'ZBRA'),\n            ('logreturn', 'ZION'),\n            ('logreturn',  'ZTS')],\n           length=495)"
     ]
    }
   ],
   "source": [
    "# Getting the log returns from stock prices\n",
    "logret = np.log(rawdata['Close']).diff()\n",
    "logret.columns = pd.MultiIndex.from_product([['logreturn'], logret.columns])\n",
    "# Joining logret and rawdata \n",
    "rawdata = rawdata.join(logret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "familiar-healthcare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After preprocessing the data, we have idenified the log returns of 495 companies, which were included in S&P500 in 2021. To recap, we are examining the stock returns from 2018 to May 2021. Therefore, we will be examining the stock returns of 857 days\n"
     ]
    }
   ],
   "source": [
    "print(\"After preprocessing the data, we have idenified the log returns of {} companies, which were included in S&P500 in 2021. To recap, we are examining the stock returns from 2018 to May 2021. Therefore, we will be examining the stock returns of {} days\".format(len(logret.columns), len(logret)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-casting",
   "metadata": {},
   "source": [
    "#### Creating a new columns for the industry information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "quantitative-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the information about the tickers that are included in SP_ticker_2017\n",
    "industry_dic = dict()\n",
    "for item in SP_ticker_2020:\n",
    "    try:\n",
    "        industry_dic[item] = yf.Ticker(item).info['industry']\n",
    "    except:\n",
    "        industry_dic[item] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "amber-astrology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">Adj Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">logreturn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Diagnostics &amp; Research</th>\n",
       "      <th>Airlines</th>\n",
       "      <th>Specialty Retail</th>\n",
       "      <th>Consumer Electronics</th>\n",
       "      <th>Drug Manufacturers—General</th>\n",
       "      <th>Medical Distribution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Medical Devices</th>\n",
       "      <th>Information Technology Services</th>\n",
       "      <th>Software—Infrastructure</th>\n",
       "      <th>...</th>\n",
       "      <th>Utilities—Regulated Electric</th>\n",
       "      <th>Semiconductors</th>\n",
       "      <th>Oil &amp; Gas Integrated</th>\n",
       "      <th>Medical Instruments &amp; Supplies</th>\n",
       "      <th>Specialty Industrial Machinery</th>\n",
       "      <th>Restaurants</th>\n",
       "      <th>Medical Devices</th>\n",
       "      <th>Communication Equipment</th>\n",
       "      <th>Banks—Regional</th>\n",
       "      <th>Drug Manufacturers—Specialty &amp; Generic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>65.777748</td>\n",
       "      <td>51.647556</td>\n",
       "      <td>104.610184</td>\n",
       "      <td>41.310070</td>\n",
       "      <td>81.751373</td>\n",
       "      <td>88.406036</td>\n",
       "      <td>192.490005</td>\n",
       "      <td>55.480598</td>\n",
       "      <td>145.921112</td>\n",
       "      <td>177.699997</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>67.451401</td>\n",
       "      <td>51.014027</td>\n",
       "      <td>105.556801</td>\n",
       "      <td>41.302879</td>\n",
       "      <td>83.030678</td>\n",
       "      <td>88.735046</td>\n",
       "      <td>195.820007</td>\n",
       "      <td>55.603271</td>\n",
       "      <td>146.594574</td>\n",
       "      <td>181.039993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006716</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>0.019450</td>\n",
       "      <td>-0.003431</td>\n",
       "      <td>0.012120</td>\n",
       "      <td>-0.000858</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>0.019668</td>\n",
       "      <td>-0.001184</td>\n",
       "      <td>0.004588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>66.945419</td>\n",
       "      <td>51.335667</td>\n",
       "      <td>109.451698</td>\n",
       "      <td>41.494736</td>\n",
       "      <td>82.557167</td>\n",
       "      <td>88.537621</td>\n",
       "      <td>199.250000</td>\n",
       "      <td>55.508900</td>\n",
       "      <td>148.330338</td>\n",
       "      <td>183.220001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007822</td>\n",
       "      <td>0.017892</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>0.006654</td>\n",
       "      <td>0.010129</td>\n",
       "      <td>-0.001442</td>\n",
       "      <td>0.019567</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.005946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>68.015762</td>\n",
       "      <td>51.316177</td>\n",
       "      <td>110.615242</td>\n",
       "      <td>41.967163</td>\n",
       "      <td>83.994331</td>\n",
       "      <td>89.609322</td>\n",
       "      <td>202.320007</td>\n",
       "      <td>55.669323</td>\n",
       "      <td>149.553955</td>\n",
       "      <td>185.339996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007028</td>\n",
       "      <td>0.050619</td>\n",
       "      <td>-0.000807</td>\n",
       "      <td>0.013953</td>\n",
       "      <td>-0.001876</td>\n",
       "      <td>0.005811</td>\n",
       "      <td>0.009892</td>\n",
       "      <td>0.015456</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.011379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>68.161713</td>\n",
       "      <td>50.809345</td>\n",
       "      <td>109.836258</td>\n",
       "      <td>41.811283</td>\n",
       "      <td>82.648544</td>\n",
       "      <td>91.094681</td>\n",
       "      <td>207.800003</td>\n",
       "      <td>55.508900</td>\n",
       "      <td>150.749115</td>\n",
       "      <td>185.039993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>0.006586</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>0.006758</td>\n",
       "      <td>0.003605</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>-0.004927</td>\n",
       "      <td>0.011924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3465 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Adj Close                              \\\n",
       "           Diagnostics & Research   Airlines Specialty Retail   \n",
       "                                A        AAL              AAP   \n",
       "Date                                                            \n",
       "2018-01-02              65.777748  51.647556       104.610184   \n",
       "2018-01-03              67.451401  51.014027       105.556801   \n",
       "2018-01-04              66.945419  51.335667       109.451698   \n",
       "2018-01-05              68.015762  51.316177       110.615242   \n",
       "2018-01-08              68.161713  50.809345       109.836258   \n",
       "\n",
       "                                                            \\\n",
       "           Consumer Electronics Drug Manufacturers—General   \n",
       "                           AAPL                       ABBV   \n",
       "Date                                                         \n",
       "2018-01-02            41.310070                  81.751373   \n",
       "2018-01-03            41.302879                  83.030678   \n",
       "2018-01-04            41.494736                  82.557167   \n",
       "2018-01-05            41.967163                  83.994331   \n",
       "2018-01-08            41.811283                  82.648544   \n",
       "\n",
       "                                                            \\\n",
       "           Medical Distribution Medical Devices              \n",
       "                            ABC            ABMD        ABT   \n",
       "Date                                                         \n",
       "2018-01-02            88.406036      192.490005  55.480598   \n",
       "2018-01-03            88.735046      195.820007  55.603271   \n",
       "2018-01-04            88.537621      199.250000  55.508900   \n",
       "2018-01-05            89.609322      202.320007  55.669323   \n",
       "2018-01-08            91.094681      207.800003  55.508900   \n",
       "\n",
       "                                                                    ...  \\\n",
       "           Information Technology Services Software—Infrastructure  ...   \n",
       "                                       ACN                    ADBE  ...   \n",
       "Date                                                                ...   \n",
       "2018-01-02                      145.921112              177.699997  ...   \n",
       "2018-01-03                      146.594574              181.039993  ...   \n",
       "2018-01-04                      148.330338              183.220001  ...   \n",
       "2018-01-05                      149.553955              185.339996  ...   \n",
       "2018-01-08                      150.749115              185.039993  ...   \n",
       "\n",
       "                              logreturn                                      \\\n",
       "           Utilities—Regulated Electric Semiconductors Oil & Gas Integrated   \n",
       "                                    XEL           XLNX                  XOM   \n",
       "Date                                                                          \n",
       "2018-01-02                          NaN            NaN                  NaN   \n",
       "2018-01-03                    -0.006716       0.019837             0.019450   \n",
       "2018-01-04                    -0.007822       0.017892             0.001383   \n",
       "2018-01-05                    -0.007028       0.050619            -0.000807   \n",
       "2018-01-08                     0.007452       0.006586             0.004486   \n",
       "\n",
       "                                                                          \\\n",
       "           Medical Instruments & Supplies Specialty Industrial Machinery   \n",
       "                                     XRAY                            XYL   \n",
       "Date                                                                       \n",
       "2018-01-02                            NaN                            NaN   \n",
       "2018-01-03                      -0.003431                       0.012120   \n",
       "2018-01-04                      -0.000149                       0.006654   \n",
       "2018-01-05                       0.013953                      -0.001876   \n",
       "2018-01-08                       0.006758                       0.003605   \n",
       "\n",
       "                                                                               \\\n",
       "           Restaurants Medical Devices Communication Equipment Banks—Regional   \n",
       "                   YUM             ZBH                    ZBRA           ZION   \n",
       "Date                                                                            \n",
       "2018-01-02         NaN             NaN                     NaN            NaN   \n",
       "2018-01-03   -0.000858        0.006908                0.019668      -0.001184   \n",
       "2018-01-04    0.010129       -0.001442                0.019567       0.004138   \n",
       "2018-01-05    0.005811        0.009892                0.015456       0.000393   \n",
       "2018-01-08    0.001689        0.001903                0.009901      -0.004927   \n",
       "\n",
       "                                                   \n",
       "           Drug Manufacturers—Specialty & Generic  \n",
       "                                              ZTS  \n",
       "Date                                               \n",
       "2018-01-02                                    NaN  \n",
       "2018-01-03                               0.004588  \n",
       "2018-01-04                               0.005946  \n",
       "2018-01-05                               0.011379  \n",
       "2018-01-08                               0.011924  \n",
       "\n",
       "[5 rows x 3465 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the industry to a level of the column\n",
    "rawdata.columns = pd.MultiIndex.from_tuples([(value, industry_dic[ticker], ticker) for value, ticker in rawdata.columns])\n",
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-skill",
   "metadata": {},
   "source": [
    "#### Creating a new columns for days of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "environmental-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The day of the week is added as a new index (creating a hierarchical index)\n",
    "rawdata['days'] = [calendar.day_name[day.weekday()] for day in rawdata.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-graphics",
   "metadata": {},
   "source": [
    "#### Exporting dataframe as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "loaded-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata.to_csv('SP500_2018_2021_multilevel.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-mercury",
   "metadata": {},
   "source": [
    "#### Staking the Closing and Log returns into one dataframe\n",
    "\n",
    "For convenience in running some of the statistical analyses, the multilevel data of stock values are stacked into a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "voluntary-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To easily stack the data, it is easier to delete the days and industry information.\n",
    "rawdata = rawdata.drop('days', axis =1)\n",
    "rawdata.columns = rawdata.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "exciting-flood",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-3ffa4795927f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Industry information is added as a new column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mstacked_rawdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Industry'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindustry_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mticker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstacked_rawdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ticker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mstacked_rawdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-3ffa4795927f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Industry information is added as a new column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mstacked_rawdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Industry'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindustry_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mticker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstacked_rawdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ticker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mstacked_rawdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "# The data is stacked \n",
    "stacked_rawdata = rawdata.stack()\n",
    "stacked_rawdata.reset_index(inplace=True)\n",
    "stacked_rawdata = stacked_rawdata.rename(columns = {'level_1':'Ticker'})\n",
    "\n",
    "# Days are added as a new column\n",
    "stacked_rawdata['days'] = [calendar.day_name[day.weekday()] for day in stacked_rawdata['Date']]\n",
    "\n",
    "# Industry information is added as a new column\n",
    "stacked_rawdata['Industry'] = [industry_dic[ticker] for ticker in stacked_rawdata['Ticker']]\n",
    "stacked_rawdata.head()\n",
    "\n",
    "# Before we forget, let's add the days and industry column back to our rawdata. We will comeback to this later\n",
    "rawdata.columns = pd.MultiIndex.from_tuples([(value, industry_dic[ticker], ticker) for value, ticker in rawdata.columns])\n",
    "rawdata['days'] = [calendar.day_name[day.weekday()] for day in rawdata.index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-delight",
   "metadata": {},
   "source": [
    "#### Exporting dataframe as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "vanilla-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_rawdata.to_csv('SP500_2018_2021_stacked.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-hammer",
   "metadata": {},
   "source": [
    "### Analyzing the Monday Effect\n",
    "The next step is to analyze the Monday effect. First, as done in Arman and Lestari's research, one-sample t-test is conducted for each day of the week. The test value is 0. Therefore, a significant result indicates that it is highly unlikely to have obtained the average log stock returns on a specific day of the week given that the null hypothesis is true (i.e. the average log stock return is 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-script",
   "metadata": {},
   "source": [
    "##### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "seven-serbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3465 columns in our dataset\n",
      "Is days one of the columns? False\n"
     ]
    }
   ],
   "source": [
    "# Let's examine how many columns we have\n",
    "print('There are {} columns in our dataset'.format(len(rawdata.columns)))\n",
    "# The days of the week is one of the columns\n",
    "print('Is days one of the columns?','days' in rawdata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "silent-triple",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['days'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-2bf75e473d7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Before we move on, let's make a multilevel index for the rows.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrawdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'days'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   4553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4555\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['days'] are in the columns\""
     ]
    }
   ],
   "source": [
    "# Before we move on, let's make a multilevel index for the rows.\n",
    "rawdata.set_index('days', append=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "hybrid-quilt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "days\n",
       "Friday       170.0\n",
       "Monday       163.0\n",
       "Thursday     174.0\n",
       "Tuesday      175.0\n",
       "Wednesday    174.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency count for each day\n",
    "rawdata['logreturn'].groupby(level=1).count().mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "continent-malawi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "days\n",
       "Thursday    -0.000048\n",
       "Monday      -0.000022\n",
       "Wednesday    0.000064\n",
       "Friday       0.001077\n",
       "Tuesday      0.001108\n",
       "dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before we get into conducting one sample t-test, \n",
    "# let's look at the mean of log stock returns for each day of the week\n",
    "rawdata['logreturn'].groupby(level=1).mean().mean(axis=1).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "blocked-canvas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "days\n",
       "Tuesday      0.005929\n",
       "Friday       0.006209\n",
       "Thursday     0.006756\n",
       "Wednesday    0.007444\n",
       "Monday       0.008791\n",
       "dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the standard deviation of log stock returns for each day of the week\n",
    "rawdata['logreturn'].groupby(level=1).std().std(axis=1).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-blanket",
   "metadata": {},
   "source": [
    "Although less tha Thursday, Monday has a negative log stock returns and a largest variance. Let's see if this value is statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-glory",
   "metadata": {},
   "source": [
    "##### Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-sussex",
   "metadata": {},
   "source": [
    "###### t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "hazardous-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_sample_t(day):\n",
    "    a = rawdata.xs(day, level='days').logreturn.values.flatten()\n",
    "    a = a[~numpy.isnan(a)]\n",
    "    return stats.ttest_1samp(a,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "purple-increase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=-0.21902829372216906, pvalue=0.8266285616536038)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-sample t-test for Monday\n",
    "one_sample_t('Monday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "regulated-shower",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=14.19998541482364, pvalue=1.0314077682210805e-45)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-sample t-test for Tuesday\n",
    "one_sample_t('Tuesday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "brazilian-mortgage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=0.7698756095608359, pvalue=0.4413757947758502)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-sample t-test for Wednesday\n",
    "one_sample_t('Wednesday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "willing-creature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=-0.5764213993864189, pvalue=0.5643318898456581)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-sample t-test for Thursday\n",
    "one_sample_t('Thursday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "affiliated-injury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=14.226349283101952, pvalue=7.10881134086702e-46)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-sample t-test for Friday\n",
    "one_sample_t('Friday')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-louisiana",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-buddy",
   "metadata": {},
   "source": [
    "## Tackling Objective 2 <a clas =\"anchor\" id = \"tackling-objective-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seven-chosen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "import rpy2\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-graphic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
